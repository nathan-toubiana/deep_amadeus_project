{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.rnn import RNNCell\n",
    "from tensorflow.python.ops import variable_scope as vs\n",
    "from tensorflow.python.ops import nn_ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "\n",
    "from func.midi_to_statematrix import *\n",
    "from func.data import *\n",
    "import func.multi_training\n",
    "\n",
    "import random\n",
    "\n",
    "import os\n",
    "#import cPickle as pickle\n",
    "import pickle\n",
    "\n",
    "import signal\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "path = os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded alb_esp2\n",
      "Loaded alb_esp5\n",
      "Loaded appass_2\n",
      "Loaded appass_3\n",
      "Loaded bach_846\n",
      "Loaded bach_847\n",
      "Loaded bach_850\n",
      "Loaded beethoven_hammerklavier_1\n",
      "Loaded beethoven_les_adieux_1\n",
      "Loaded beethoven_les_adieux_2\n",
      "Loaded beethoven_opus10_2\n",
      "Loaded beethoven_opus10_3\n",
      "Loaded beethoven_opus22_1\n",
      "Loaded beethoven_opus22_4\n",
      "Loaded beethoven_opus90_2\n"
     ]
    }
   ],
   "source": [
    "pcs = func.multi_training.loadPieces(path  + '/music_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_width = 10 # number of sequences in a batch\n",
    "batch_len = 16*8 # length of each sequence\n",
    "division_len = 16 # interval between possible start locations\n",
    "\n",
    "def loadPieces(dirpath):\n",
    "\n",
    "    pieces = {}\n",
    "\n",
    "    for fname in os.listdir(dirpath):\n",
    "        if fname[-4:] not in ('.mid','.MID'):\n",
    "            continue\n",
    "\n",
    "        name = fname[:-4]\n",
    "\n",
    "        outMatrix = midiToNoteStateMatrix(os.path.join(dirpath, fname))\n",
    "        if len(outMatrix) < batch_len:\n",
    "            continue\n",
    "\n",
    "        pieces[name] = outMatrix\n",
    "        print(\"Loaded {}\".format(name))\n",
    "\n",
    "    return pieces\n",
    "\n",
    "def getPieceSegment(pieces):\n",
    "    pcs=pieces.values()\n",
    "    piece_output = random.choice(list(pcs))\n",
    "    start = random.randrange(0,len(piece_output)-batch_len,division_len)\n",
    "    \n",
    "    # print \"Range is {} {} {} -> {}\".format(0,len(piece_output)-batch_len,division_len, start)\n",
    "\n",
    "    seg_out = piece_output[start:start+batch_len]\n",
    "    seg_in = noteStateMatrixToInputForm(seg_out)\n",
    "\n",
    "    return seg_in, seg_out\n",
    "\n",
    "def getPieceBatch(pieces):\n",
    "    i,o = zip(*[getPieceSegment(pieces) for _ in range(batch_width)])\n",
    "    return numpy.array(i), numpy.array(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainPiece(model,pieces,epochs,start=0):\n",
    "    stopflag = [False]\n",
    "    def signal_handler(signame, sf):\n",
    "        stopflag[0] = True\n",
    "    old_handler = signal.signal(signal.SIGINT, signal_handler)\n",
    "    for i in range(start,start+epochs):\n",
    "        if stopflag[0]:\n",
    "            break\n",
    "        error = model.update_fun(*getPieceBatch(pieces))\n",
    "        if i % 100 == 0:\n",
    "            print(\"epoch {}, error={}\".format(i,error))\n",
    "        if i % 500 == 0 or (i % 100 == 0 and i < 1000):\n",
    "            xIpt, xOpt = map(numpy.array, getPieceSegment(pieces))\n",
    "            noteStateMatrixToMidi(numpy.concatenate((numpy.expand_dims(xOpt[0], 0), model.predict_fun(batch_len, 1, xIpt[0])), axis=0),'output/sample{}'.format(i))\n",
    "            pickle.dump(model.learned_config,open('output/params{}.p'.format(i), 'wb'))\n",
    "    signal.signal(signal.SIGINT, old_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song={}\n",
    "song['beethoven_hammerklavier_1']=pcs['beethoven_hammerklavier_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Model(t_layer_sizes,p_layer_sizes,xs,ys):\n",
    "\n",
    "    t_input_size = 80\n",
    "\n",
    "    \n",
    "\n",
    "            #Lstm input data recquires size : batch_size,max_time (spanning back how many time steps), ect..\n",
    "    \n",
    "            #xs = tf.one_hot(xss, depth=1000, axis=-1)\n",
    "            #xs_onehot = tf.one_hot(xs, depth=1000, axis=-1)\n",
    "\n",
    "            # From our architecture definition, size of the notewise input\n",
    "\n",
    "            # time network maps from notewise input size to various hidden sizes\n",
    "    lstm_time=[]\n",
    "    for i in t_layer_sizes:\n",
    "        lstm_time.append(tf.contrib.rnn.LSTMCell(i))\n",
    "\n",
    "    time_model=tf.contrib.rnn.MultiRNNCell(lstm_time)        \n",
    "    init_state_time=time_model.zero_state(tf.shape(ys)[0],tf.float32)\n",
    "    with tf.variable_scope('lstm1'):\n",
    "        outputs_time,final_state_time=tf.nn.dynamic_rnn(time_model, xs, initial_state = init_state_time, dtype = tf.float32)\n",
    "            #self.time_model = StackedCells( self.t_input_size, celltype=LSTM, layers = t_layer_sizes)\n",
    "            #self.time_model.layers.append(PassthroughLayer())\n",
    "\n",
    "            # pitch network takes last layer of time model and state of last note, moving upward\n",
    "            # and eventually ends with a two-element sigmoid layer\n",
    "\n",
    "    p_input_size = t_layer_sizes[-1] + 2\n",
    "\n",
    "\n",
    "    lstm_pitch=[]\n",
    "\n",
    "    for i in p_layer_sizes:\n",
    "        lstm_pitch.append(tf.contrib.rnn.LSTMCell(i))\n",
    "    lstm_pitch.append(tf.contrib.rnn.LSTMCell(2))\n",
    "\n",
    "\n",
    "    pitch_model=tf.contrib.rnn.MultiRNNCell(lstm_pitch)\n",
    "\n",
    "    init_state_pitch=pitch_model.zero_state(tf.shape(ys)[0],tf.float32)\n",
    "    with tf.variable_scope('lstm2'):\n",
    "        outputs_pitch,final_state_pitch=tf.nn.dynamic_rnn(pitch_model,outputs_time,initial_state = init_state_pitch,dtype = tf.float32)\n",
    "\n",
    "    loss=tf.nn.sigmoid_cross_entropy_with_logits(labels=ys,logits=outputs_pitch)\n",
    "    #loss=tf.reduce_mean(loss)\n",
    "        \n",
    "        \n",
    "        \n",
    "    return outputs_pitch,loss\n",
    "\n",
    "\n",
    "def cross_entropy(output, input_y):\n",
    "    with tf.name_scope('cross_entropy'):\n",
    "        \n",
    "        ce = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=ys, logits=output))\n",
    "\n",
    "    return ce\n",
    "\n",
    "\n",
    "def train_step(loss, learning_rate=1e-3):\n",
    "    with tf.name_scope('train_step'):\n",
    "        step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "    return step\n",
    "\n",
    "\n",
    "def evaluate(output, input_y):\n",
    "    with tf.name_scope('evaluate'):\n",
    "        pred = tf.argmax(output, axis=1)\n",
    "        error_num = tf.count_nonzero(pred - tf.cast(input_y, tf.int64), name='error_num')\n",
    "        #tf.summary.scalar('LeNet_error_num', error_num)\n",
    "    return error_num\n",
    "\n",
    "def training(song,t_layer_sizes,p_layer_sizes, pre_trained_model=None):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    # define the variables and parameter needed during training\n",
    "    with tf.name_scope('inputs'):\n",
    "        xs = tf.placeholder(tf.float32, [None,None, t_input_size])\n",
    "        ys = tf.placeholder(tf.float32, [None,None, 2])\n",
    "        \n",
    "        \n",
    "    output, loss = Model(t_layer_sizes,p_layer_sizes,xs,ys)\n",
    "    \n",
    "    \n",
    "    iters = int(np.array(list(song.values())[0]).shape[0] / batch_len)\n",
    "    print('number of batches for training: {}'.format(iters))\n",
    "\n",
    "    step = train_step(loss)\n",
    "    eve = evaluate(output, ys)\n",
    "\n",
    "    iter_total = 0\n",
    "    best_acc = 0\n",
    "    #cur_model_name = 'lenet_{}'.format(int(time.time()))\n",
    "\n",
    "    epoch=20\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        #merge = tf.summary.merge_all()\n",
    "\n",
    "        #writer = tf.summary.FileWriter(\"log/{}\".format(cur_model_name), sess.graph)\n",
    "        #saver = tf.train.Saver()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # try to restore the pre_trained\n",
    "        if pre_trained_model is not None:\n",
    "            try:\n",
    "                print(\"Load the model from: {}\".format(pre_trained_model))\n",
    "                saver.restore(sess, 'model/{}'.format(pre_trained_model))\n",
    "            except Exception:\n",
    "                print(\"Load model Failed!\")\n",
    "                pass\n",
    "\n",
    "        for epc in range(epoch):\n",
    "            print(\"epoch {} \".format(epc + 1))\n",
    "\n",
    "            for itr in range(iters):\n",
    "                iter_total += 1\n",
    "                training_batch_x,training_batch_y= map(numpy.array, getPieceSegment(song))\n",
    "                \n",
    "                _, cur_loss = sess.run([step, loss], feed_dict={xs: training_batch_x, ys: training_batch_y})\n",
    "                print(cur_loss)\n",
    "                break\n",
    "            break\n",
    "                    # save the merge result summary\n",
    "                #writer.add_summary(merge_result, iter_total)\n",
    "\n",
    "                    # when achieve the best validation accuracy, we store the model paramters\n",
    "                    \n",
    "\n",
    "    #print(\"Traning ends. The best valid accuracy is {}. Model named {}.\".format(best_acc, cur_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_input_size=80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of batches for training: 33\n",
      "epoch 1 \n",
      "[[[ 0.69311529  0.69311827]\n",
      "  [ 0.69297081  0.69302309]\n",
      "  [ 0.69260359  0.69282448]\n",
      "  ..., \n",
      "  [ 0.58242041  0.62922245]\n",
      "  [ 0.58260369  0.62931722]\n",
      "  [ 0.58278167  0.62940717]]\n",
      "\n",
      " [[ 0.69312429  0.69311476]\n",
      "  [ 0.69300181  0.69302177]\n",
      "  [ 0.69266331  0.69283658]\n",
      "  ..., \n",
      "  [ 0.57414371  0.62025809]\n",
      "  [ 0.5742377   0.62033588]\n",
      "  [ 0.57434899  0.62042552]]\n",
      "\n",
      " [[ 0.69312763  0.69314182]\n",
      "  [ 0.69304109  0.6931318 ]\n",
      "  [ 0.69281811  0.69312292]\n",
      "  ..., \n",
      "  [ 0.59133685  0.63761163]\n",
      "  [ 0.5913918   0.63752311]\n",
      "  [ 0.59144253  0.63744259]]\n",
      "\n",
      " ..., \n",
      " [[ 0.69314843  0.69311881]\n",
      "  [ 0.69312876  0.69300878]\n",
      "  [ 0.69300967  0.69274551]\n",
      "  ..., \n",
      "  [ 0.56003022  0.6106264 ]\n",
      "  [ 0.55985695  0.61066884]\n",
      "  [ 0.55972266  0.61070776]]\n",
      "\n",
      " [[ 0.69317102  0.69314247]\n",
      "  [ 0.69322014  0.69311678]\n",
      "  [ 0.69326144  0.69302922]\n",
      "  ..., \n",
      "  [ 0.58002663  0.62865454]\n",
      "  [ 0.58014572  0.62870789]\n",
      "  [ 0.58026892  0.62876314]]\n",
      "\n",
      " [[ 0.69316024  0.69314599]\n",
      "  [ 0.69318157  0.69312871]\n",
      "  [ 0.69317752  0.69306999]\n",
      "  ..., \n",
      "  [ 0.56909555  0.61956215]\n",
      "  [ 0.56915444  0.61948723]\n",
      "  [ 0.569251    0.6194374 ]]]\n"
     ]
    }
   ],
   "source": [
    "a=training(song,[300,300],[100,50], pre_trained_model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
