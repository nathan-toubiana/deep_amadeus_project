{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pygame\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.rnn import RNNCell\n",
    "from tensorflow.python.ops import variable_scope as vs\n",
    "from tensorflow.python.ops import nn_ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from func.jupyter_tensorboard import show_graph\n",
    "\n",
    "from func.midi_to_statematrix import *\n",
    "from func.data import *\n",
    "import func.multi_training\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "#import cPickle as pickle\n",
    "import pickle\n",
    "import signal\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "path = os.getcwd()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def play_music(music_file):\n",
    "    \"\"\"\n",
    "    stream music with mixer.music module in blocking manner\n",
    "    this will stream the sound from disk while playing\n",
    "    \"\"\"\n",
    "    clock = pygame.time.Clock()\n",
    "    try:\n",
    "        pygame.mixer.music.load(music_file)\n",
    "        print(\"Music file %s loaded!\" % music_file)\n",
    "    except pygame.error:\n",
    "        print(\"File %s not found! (%s)\" % (music_file, pygame.get_error()))\n",
    "        return\n",
    "    pygame.mixer.music.play()\n",
    "    while pygame.mixer.music.get_busy():\n",
    "        # check if playback has finished\n",
    "        \n",
    "        clock.tick(30)\n",
    "        pygame.quit()\n",
    "\n",
    "freq = 44100    # audio CD quality\n",
    "bitsize = -16   # unsigned 16 bit\n",
    "channels = 2    # 1 is mono, 2 is stereo\n",
    "buffer = 1024    # number of samples\n",
    "pygame.mixer.init(freq, bitsize, channels, buffer)\n",
    "# optional volume 0 to 1.0\n",
    "pygame.mixer.music.set_volume(0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "play_music(path + '/music_test/' + 'beethoven_opus10_1.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded alb_esp2\n",
      "Loaded alb_esp5\n",
      "Loaded appass_2\n",
      "Loaded appass_3\n",
      "Loaded bach_846\n",
      "Loaded bach_847\n",
      "Loaded bach_850\n",
      "Loaded beethoven_hammerklavier_1\n",
      "Loaded beethoven_les_adieux_1\n",
      "Loaded beethoven_les_adieux_2\n",
      "Loaded beethoven_opus10_2\n",
      "Loaded beethoven_opus10_3\n",
      "Loaded beethoven_opus22_1\n",
      "Loaded beethoven_opus22_4\n",
      "Loaded beethoven_opus90_2\n"
     ]
    }
   ],
   "source": [
    "pcs = func.multi_training.loadPieces(path  + '/music_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_width = 10 # number of sequences in a batch\n",
    "batch_len = 16*8 # length of each sequence\n",
    "division_len = 16 # interval between possible start locations\n",
    "\n",
    "def loadPieces(dirpath):\n",
    "\n",
    "    pieces = {}\n",
    "\n",
    "    for fname in os.listdir(dirpath):\n",
    "        if fname[-4:] not in ('.mid','.MID'):\n",
    "            continue\n",
    "\n",
    "        name = fname[:-4]\n",
    "\n",
    "        outMatrix = midiToNoteStateMatrix(os.path.join(dirpath, fname))\n",
    "        if len(outMatrix) < batch_len:\n",
    "            continue\n",
    "\n",
    "        pieces[name] = outMatrix\n",
    "        print(\"Loaded {}\".format(name))\n",
    "\n",
    "    return pieces\n",
    "\n",
    "def getPieceSegment(pieces):\n",
    "    pcs=pieces.values()\n",
    "    piece_output = random.choice(list(pcs))\n",
    "    start = random.randrange(0,len(piece_output)-batch_len,division_len)\n",
    "    \n",
    "    # print \"Range is {} {} {} -> {}\".format(0,len(piece_output)-batch_len,division_len, start)\n",
    "\n",
    "    seg_out = piece_output[start:start+batch_len]\n",
    "    seg_in = noteStateMatrixToInputForm(seg_out)\n",
    "\n",
    "    return seg_in, seg_out\n",
    "\n",
    "def getPieceBatch(pieces):\n",
    "    i,o = zip(*[getPieceSegment(pieces) for _ in range(batch_width)])\n",
    "    return numpy.array(i), numpy.array(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainPiece(model,pieces,epochs,start=0):\n",
    "    stopflag = [False]\n",
    "    def signal_handler(signame, sf):\n",
    "        stopflag[0] = True\n",
    "    old_handler = signal.signal(signal.SIGINT, signal_handler)\n",
    "    for i in range(start,start+epochs):\n",
    "        if stopflag[0]:\n",
    "            break\n",
    "        error = model.update_fun(*getPieceBatch(pieces))\n",
    "        if i % 100 == 0:\n",
    "            print(\"epoch {}, error={}\".format(i,error))\n",
    "        if i % 500 == 0 or (i % 100 == 0 and i < 1000):\n",
    "            xIpt, xOpt = map(numpy.array, getPieceSegment(pieces))\n",
    "            noteStateMatrixToMidi(numpy.concatenate((numpy.expand_dims(xOpt[0], 0), model.predict_fun(batch_len, 1, xIpt[0])), axis=0),'output/sample{}'.format(i))\n",
    "            pickle.dump(model.learned_config,open('output/params{}.p'.format(i), 'wb'))\n",
    "    signal.signal(signal.SIGINT, old_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reshape_time(x):\n",
    "    \n",
    "    input_slice = x[:,0:-1]\n",
    "    n_batch, n_time, n_note, n_ipn = input_slice.shape\n",
    "        \n",
    "    # time_inputs is a matrix (time, batch/note, input_per_note)\n",
    "    time_inputs = input_slice.transpose((1,0,2,3)).reshape((n_time,n_batch*n_note,n_ipn))\n",
    "    return time_inputs,n_batch,n_time,n_note,n_ipn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song={}\n",
    "song['beethoven_hammerklavier_1']=pcs['beethoven_hammerklavier_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a,b,c,d = [0,1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Model(t_layer_sizes,p_layer_sizes,xs,ys):\n",
    "\n",
    "    \n",
    "    #xs\n",
    "    input_slice = xs[:,0:-1]\n",
    "    \n",
    "    n_batch, n_time, n_note, n_ipn = tf.shape(input_slice)[0], tf.shape(input_slice)[1],tf.shape(input_slice)[2],input_slice.get_shape().as_list()[3]\n",
    "    \n",
    "    input_slice = tf.reshape(tf.transpose(input_slice,(1,0,2,3)),(n_time,n_batch*n_note,n_ipn))\n",
    "    \n",
    "    \n",
    "    \n",
    "    t_input_size = 80\n",
    "    lstm_time=[]\n",
    "    for i in t_layer_sizes:\n",
    "        lstm_time.append(tf.contrib.rnn.LSTMCell(i))\n",
    "\n",
    "    time_model=tf.contrib.rnn.MultiRNNCell(lstm_time)        \n",
    "    init_state_time=time_model.zero_state(tf.shape(ys)[0],tf.float32)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #output, self.final_state = tf.nn.dynamic_rnn(...)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    with tf.variable_scope('lstm1'):\n",
    "        #tf.get_variable\n",
    "        outputs_time,final_state_time=tf.nn.dynamic_rnn(time_model, input_slice, dtype = tf.float32)\n",
    "        for one_lstm_cell in lstm_time:\n",
    "            one_kernel, one_bias = one_lstm_cell.variables\n",
    "            # I think TensorBoard handles summaries with the same name fine.\n",
    "            tf.summary.histogram(\"Kernel-time\", one_kernel)\n",
    "            tf.summary.histogram(\"Bias-time\", one_bias)    \n",
    "    p_input_size = t_layer_sizes[-1] + 2\n",
    "\n",
    "    # Transpose to be (note, batch/time, hidden_states)\n",
    "    n_hidden = outputs_time.get_shape().as_list()[2]\n",
    "   \n",
    "    time_final = tf.reshape(tf.transpose(tf.reshape(outputs_time,(n_time,n_batch,n_note,n_hidden)),(2,1,0,3)),(n_note,n_batch*n_time,n_hidden))\n",
    "    \n",
    "    #ys:\n",
    "    \n",
    "        \n",
    "    start_note_values = tf.zeros([1,tf.shape(time_final)[1] ,2], tf.float32)\n",
    "    \n",
    "    correct_choices = tf.reshape(tf.transpose(ys[:,1:,0:-1,:],(2,0,1,3)),(n_note-1,n_batch*n_time,2))\n",
    "    \n",
    "    note_choices_inputs = tf.concat([start_note_values, correct_choices], axis=0)\n",
    "    \n",
    "    \n",
    "    note_inputs = tf.concat( [time_final, note_choices_inputs], axis=2)\n",
    "    num_timebatch = note_inputs.shape[1]\n",
    "    \n",
    "    \n",
    "    # note_choices_inputs represents the last chosen note. Starts with [0,0], doesn't include last note.\n",
    "    # In (note, batch/time, 2) format\n",
    "    # Shape of start is thus (1, N, 2), concatenated with all but last element of output_mat transformed to (x, N, 2)\n",
    "    ##start_note_values = T.alloc(np.array(0,dtype=np.int8), 1, tf.shape(time_final)[1], 2 )\n",
    "    ##correct_choices = self.output_mat[:,1:,0:-1,:].transpose((2,0,1,3)).reshape((n_note-1,n_batch*n_time,2))\n",
    "    ##note_choices_inputs = T.concatenate([start_note_values, correct_choices], axis=0)\n",
    "        \n",
    "    # Together, this and the output from the last LSTM goes to the new LSTM, but rotated, so that the batches in\n",
    "    # one direction are the steps in the other, and vice versa.\n",
    "    ##note_inputs = T.concatenate( [time_final, note_choices_inputs], axis=2 )\n",
    "    ##num_timebatch = note_inputs.shape[1]\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    lstm_pitch=[]\n",
    "\n",
    "    for i in p_layer_sizes:\n",
    "        lstm_pitch.append(tf.contrib.rnn.LSTMCell(i))\n",
    "    lstm_pitch.append(tf.contrib.rnn.LSTMCell(2))\n",
    "\n",
    "\n",
    "    pitch_model=tf.contrib.rnn.MultiRNNCell(lstm_pitch)\n",
    "    \n",
    "    init_state_pitch=pitch_model.zero_state(tf.shape(note_inputs)[0],tf.float32)\n",
    "    with tf.variable_scope('lstm2'):\n",
    "        outputs_pitch,final_state_pitch=tf.nn.dynamic_rnn(pitch_model,note_inputs,dtype = tf.float32)\n",
    "        for one_lstm_cell in lstm_pitch:\n",
    "            one_kernel, one_bias = one_lstm_cell.variables\n",
    "            # I think TensorBoard handles summaries with the same name fine.\n",
    "            \n",
    "            tf.summary.histogram(\"Kernel-pitch\", one_kernel)\n",
    "            tf.summary.histogram(\"Bias-pitch\", one_bias)    \n",
    "        #variables_names =[v.name for v in tf.trainable_variables()]\n",
    "        #values = sess.run(variables_names)\n",
    "                \n",
    "        #for k,v in zip(variables_names, values):\n",
    "            #tf.summary.histogram('parameters/{}'.format(k),v)\n",
    "    #note_final = get_last_layer(note_result).reshape((n_note,n_batch,n_time,2)).transpose(1,2,0,3)\n",
    "    outputs_pitch = tf.transpose(tf.reshape(outputs_pitch,(n_note,n_batch,n_time,2)),(1,2,0,3)) \n",
    "    \n",
    "    #ys is output_mat\n",
    "    #outputs_pitch is note_final\n",
    "    \n",
    "    #ce=tf.multiply(-1.0,tf.reduce_mean(tf.log(tf.add(tf.add(tf.add(tf.multiply(2.0, tf.cast(outputs_pitch*ys[:,1:],tf.float32)) ,tf.cast(outputs_pitch,tf.float32)), tf.cast(ys[:,1:],tf.float32)),  1.0) )))\n",
    "    \n",
    "    \n",
    "    #2*outputs_pitch*ys[:,1:] - outputs_pitch - ys[:,1:] + 1\n",
    "    \n",
    "    #first\n",
    "    term_1=tf.multiply(2.0,tf.multiply(tf.sigmoid(outputs_pitch),ys[:,1:]))\n",
    "    term_2=tf.multiply(-1.0,tf.sigmoid(outputs_pitch))\n",
    "    term_3=tf.multiply(-1.0,ys[:,1:])\n",
    "    \n",
    "    term_4=tf.add(term_1,term_2)\n",
    "    term_5=tf.add(term_4,term_3)\n",
    "    term_6=tf.add(1.0,term_5)\n",
    "    \n",
    "    term_7=tf.log(term_6)\n",
    "    term_8=tf.reduce_mean(term_7)\n",
    "    \n",
    "    term_9=tf.multiply(-1.0,term_8)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #ce=tf.reduce_mean(tf.log(tf.add(tf.add(tf.add(tf.multiply(2.0, tf.cast(outputs_pitch*ys[:,1:],tf.float32)) ,tf.multiply(tf.cast(outputs_pitch,tf.float32),-1.0)), tf.multiply( tf.cast(ys[:,1:],tf.float32),-1.0)),  1.0) ))\n",
    "    #ce=-tf.reduce_mean(tf.log(2*outputs_pitch*ys[:,1:] - outputs_pitch - ys[:,1:] + 1 ))\n",
    "    return (outputs_pitch,term_9)\n",
    "\n",
    "\n",
    "def cross_entropy(output, input_y):\n",
    "    with tf.name_scope('cross_entropy'):\n",
    "        \n",
    "        \n",
    "        ce = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=input_y[:,1:], logits=output))\n",
    "        \n",
    "    return ce\n",
    "\n",
    "\n",
    "def train_step(loss, learning_rate=1e-3):\n",
    "    with tf.name_scope('train_step'):\n",
    "        step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "    return step\n",
    "\n",
    "\n",
    "def evaluate(output, input_y):\n",
    "    with tf.name_scope('evaluate'):\n",
    "        pred = tf.argmax(output, axis=1)\n",
    "        error_num = tf.count_nonzero(pred - tf.cast(input_y, tf.int64), name='error_num')\n",
    "        \n",
    "    return error_num\n",
    "\n",
    "def training(song,t_layer_sizes,p_layer_sizes, pre_trained_model=None):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    # define the variables and parameter needed during training\n",
    "    with tf.name_scope('inputs'):\n",
    "        xs = tf.placeholder(tf.float32, [None,None,None, t_input_size])\n",
    "        ys = tf.placeholder(tf.float32, [None,None,None, 2])\n",
    "    m= Model(t_layer_sizes,p_layer_sizes,xs,ys) \n",
    "    output= m[0]\n",
    "    \n",
    "    print(output.shape)\n",
    "    loss=m[1]\n",
    "    #loss=cross_entropy(output, ys)\n",
    "    \n",
    "    iters = int(np.array(list(song.values())[0]).shape[0] / batch_len)\n",
    "    #iters=2\n",
    "    print('number of batches for training: {}'.format(iters))\n",
    "\n",
    "    step = train_step(loss)\n",
    "    eve = evaluate(output, ys)\n",
    "\n",
    "    iter_total = 0\n",
    "    best_acc = 0\n",
    "    cur_model_name = 'amadeus'\n",
    "\n",
    "    epoch=1\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        merge = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter(\"log/{}\".format(cur_model_name), sess.graph)\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        #train_writer = tf.summary.FileWriter(\"log/\", graph=tf.get_default_graph())\n",
    "\n",
    "        # try to restore the pre_trained\n",
    "        if pre_trained_model is not None:\n",
    "            try:\n",
    "                print(\"Load the model from: {}\".format(pre_trained_model))\n",
    "                saver.restore(sess, 'model_save/{}'.format(pre_trained_model))\n",
    "            except Exception:\n",
    "                print(\"Load model Failed!\")\n",
    "                pass\n",
    "\n",
    "        for epc in range(epoch):\n",
    "            print(\"epoch {} \".format(epc + 1))\n",
    "\n",
    "            for itr in range(iters):\n",
    "   \n",
    "                \n",
    "                \n",
    "                \n",
    "                training_batch_x,training_batch_y= map(numpy.array, getPieceBatch(song))\n",
    "                #xtrain,n_batch,n_time,n_note,n_ipn=reshape_time(training_batch_x)\n",
    "                #ytrain,_,_,_,_=reshape_time(training_batch_y)\n",
    "                _, cur_loss = sess.run([step, loss], feed_dict={xs: training_batch_x, ys:training_batch_y})\n",
    "                #out=sess.run(output, feed_dict={xs: training_batch_x, ys: training_batch_y})\n",
    "                \n",
    "                #variables_names =[v.name for v in tf.trainable_variables()]\n",
    "                #print(variables_names)\n",
    "                    \n",
    "                merge_result=sess.run(merge, feed_dict={xs: training_batch_x, ys: training_batch_y})\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                saver.save(sess,'model_save/{}'.format(cur_model_name))\n",
    "                \n",
    "                \n",
    "                \n",
    "                train_writer.add_summary(merge_result,itr)\n",
    "               \n",
    "                \n",
    "                print(cur_loss)\n",
    "                \n",
    "                if itr==iters-1:\n",
    "                    out=sess.run(output, feed_dict={xs: training_batch_x, ys: training_batch_y})\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    #u=noteStateMatrixToMidi(out, name=\"output\")\n",
    "                    \n",
    "                    return out\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_input_size=80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, ?, 2)\n",
      "number of batches for training: 33\n",
      "epoch 1 \n",
      "0.716203\n",
      "0.7066\n",
      "0.697048\n",
      "0.68673\n",
      "0.6774\n",
      "0.668691\n",
      "0.659611\n",
      "0.652213\n",
      "0.64457\n",
      "0.637618\n",
      "0.631845\n",
      "0.626535\n",
      "0.62153\n",
      "0.616815\n",
      "0.612021\n",
      "0.608712\n",
      "0.604914\n",
      "0.601328\n",
      "0.596423\n",
      "0.591237\n",
      "0.585229\n",
      "0.582174\n",
      "0.578902\n",
      "0.577721\n",
      "0.575391\n",
      "0.573682\n",
      "0.571926\n",
      "0.570089\n",
      "0.568151\n",
      "0.567584\n",
      "0.566515\n",
      "0.565727\n",
      "0.56282\n"
     ]
    }
   ],
   "source": [
    "a=training(song,[300,300],[100,50], pre_trained_model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.25056762, -0.40417114],\n",
       "       [-0.2394416 , -0.40448803],\n",
       "       [-0.22346891, -0.40092903],\n",
       "       [-0.20804687, -0.39344454],\n",
       "       [-0.18789391, -0.3820577 ],\n",
       "       [-0.1728268 , -0.36757389],\n",
       "       [-0.16255133, -0.35132882],\n",
       "       [-0.15626599, -0.33480337],\n",
       "       [-0.15750639, -0.31893617],\n",
       "       [-0.16328757, -0.30327019],\n",
       "       [-0.1728562 , -0.28979069],\n",
       "       [-0.18288557, -0.2778641 ],\n",
       "       [-0.19437385, -0.2663919 ],\n",
       "       [-0.20668656, -0.26051664],\n",
       "       [-0.21709837, -0.25710186],\n",
       "       [-0.22817586, -0.25540087],\n",
       "       [-0.23419763, -0.25717551],\n",
       "       [-0.24271592, -0.2617335 ],\n",
       "       [-0.24933326, -0.26824287],\n",
       "       [-0.25568137, -0.27412373],\n",
       "       [-0.26160192, -0.28287664],\n",
       "       [-0.26658174, -0.29250243],\n",
       "       [-0.27207205, -0.30091143],\n",
       "       [-0.27575022, -0.30839542],\n",
       "       [-0.27914846, -0.31374696],\n",
       "       [-0.2825343 , -0.32109359],\n",
       "       [-0.28445145, -0.32724613],\n",
       "       [-0.27919963, -0.32580498],\n",
       "       [-0.28744939, -0.34023234],\n",
       "       [-0.28863737, -0.34687379],\n",
       "       [-0.28623223, -0.34865844],\n",
       "       [-0.29078144, -0.35941547],\n",
       "       [-0.29260787, -0.3628464 ],\n",
       "       [-0.29290444, -0.36844033],\n",
       "       [-0.29449686, -0.37468892],\n",
       "       [-0.29314002, -0.37285993],\n",
       "       [-0.29625994, -0.37581125],\n",
       "       [-0.29655081, -0.38131136],\n",
       "       [-0.29625601, -0.38227874],\n",
       "       [-0.29469183, -0.38257763],\n",
       "       [-0.29807356, -0.38149276],\n",
       "       [-0.29702383, -0.3834694 ],\n",
       "       [-0.29444292, -0.39051381],\n",
       "       [-0.29683787, -0.38870776],\n",
       "       [-0.29639411, -0.38868821],\n",
       "       [-0.293432  , -0.39454114],\n",
       "       [-0.29429266, -0.39482063],\n",
       "       [-0.29281229, -0.39670229],\n",
       "       [-0.2937161 , -0.39340848],\n",
       "       [-0.29156125, -0.39634863],\n",
       "       [-0.28886235, -0.39871991],\n",
       "       [-0.28997156, -0.40202451],\n",
       "       [-0.28726459, -0.39970809],\n",
       "       [-0.28551731, -0.40057036],\n",
       "       [-0.28318229, -0.40156269],\n",
       "       [-0.28537968, -0.40207824],\n",
       "       [-0.28314659, -0.39822149],\n",
       "       [-0.28011075, -0.40177855],\n",
       "       [-0.28076434, -0.40489554],\n",
       "       [-0.27879947, -0.40130615],\n",
       "       [-0.27949369, -0.39622259],\n",
       "       [-0.27645972, -0.40072393],\n",
       "       [-0.27423573, -0.40132621],\n",
       "       [-0.27524185, -0.40499988],\n",
       "       [-0.27292567, -0.40075311],\n",
       "       [-0.27192163, -0.39934465],\n",
       "       [-0.2688486 , -0.40097365],\n",
       "       [-0.26959646, -0.40013686],\n",
       "       [-0.26901081, -0.39917439],\n",
       "       [-0.26628348, -0.40030435],\n",
       "       [-0.26595914, -0.40035766],\n",
       "       [-0.26505634, -0.39993423],\n",
       "       [-0.26422116, -0.39939168],\n",
       "       [-0.26260239, -0.39945796],\n",
       "       [-0.2612198 , -0.39910117],\n",
       "       [-0.26195395, -0.3983787 ],\n",
       "       [-0.26049396, -0.39830461],\n",
       "       [-0.25858304, -0.39856672]], dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[9][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(u.shape[0]):\n",
    "    for j in range(u.shape[1]):\n",
    "        for k in range(u.shape[2]):\n",
    "            if (u[i][j][k]>=-0.01):\n",
    "                u[i][j][k]=int(1)\n",
    "            else:\n",
    "                u[i][j][k]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_predictions(output):\n",
    "    print(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "convert_predictions(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(a.shape[0]):\n",
    "    \n",
    "    noteStateMatrixToMidi(a[i], name=\"output\"+str(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.37040362,  0.40908483],\n",
       "       [ 0.36755195,  0.40925404],\n",
       "       [ 0.36170253,  0.40837231],\n",
       "       [ 0.3560617 ,  0.40561283],\n",
       "       [ 0.34812027,  0.40247095],\n",
       "       [ 0.34115115,  0.39772391],\n",
       "       [ 0.33381495,  0.39364222],\n",
       "       [ 0.3277202 ,  0.38734758],\n",
       "       [ 0.32576615,  0.38102186],\n",
       "       [ 0.32767773,  0.37218866],\n",
       "       [ 0.33295134,  0.36143649],\n",
       "       [ 0.33928391,  0.35086879],\n",
       "       [ 0.34780291,  0.34026527],\n",
       "       [ 0.35637474,  0.32949015],\n",
       "       [ 0.36285746,  0.32135764],\n",
       "       [ 0.37163585,  0.31198409],\n",
       "       [ 0.37798977,  0.30646452],\n",
       "       [ 0.38574812,  0.2993013 ],\n",
       "       [ 0.39108843,  0.29767367],\n",
       "       [ 0.3939552 ,  0.29714197],\n",
       "       [ 0.3963429 ,  0.30069649],\n",
       "       [ 0.39912614,  0.30352744],\n",
       "       [ 0.40130192,  0.30564278],\n",
       "       [ 0.40158674,  0.31167349],\n",
       "       [ 0.40207464,  0.31722325],\n",
       "       [ 0.4016588 ,  0.32252705],\n",
       "       [ 0.39989945,  0.33097124],\n",
       "       [ 0.40070662,  0.33540243],\n",
       "       [ 0.39871579,  0.34401253],\n",
       "       [ 0.3993082 ,  0.34759194],\n",
       "       [ 0.39809862,  0.35366917],\n",
       "       [ 0.39649898,  0.35767949],\n",
       "       [ 0.40088156,  0.35750303],\n",
       "       [ 0.3937248 ,  0.36683655],\n",
       "       [ 0.40110961,  0.36602733],\n",
       "       [ 0.39116254,  0.37264302],\n",
       "       [ 0.39045426,  0.37504634],\n",
       "       [ 0.3884545 ,  0.3783212 ],\n",
       "       [ 0.38643441,  0.38182575],\n",
       "       [ 0.39098707,  0.38392496],\n",
       "       [ 0.38527468,  0.38578358],\n",
       "       [ 0.39151156,  0.38385874],\n",
       "       [ 0.38476849,  0.38843197],\n",
       "       [ 0.38803831,  0.38790834],\n",
       "       [ 0.38573813,  0.38975036],\n",
       "       [ 0.38185617,  0.39262962],\n",
       "       [ 0.38766712,  0.39326298],\n",
       "       [ 0.38071483,  0.39405265],\n",
       "       [ 0.38197568,  0.39507622],\n",
       "       [ 0.37996113,  0.395861  ],\n",
       "       [ 0.37896964,  0.39709571],\n",
       "       [ 0.37940952,  0.39730883],\n",
       "       [ 0.37893033,  0.39817184],\n",
       "       [ 0.38400713,  0.39817214],\n",
       "       [ 0.37932584,  0.39888513],\n",
       "       [ 0.38368604,  0.39926928],\n",
       "       [ 0.38879123,  0.39976537],\n",
       "       [ 0.37856534,  0.40052417],\n",
       "       [ 0.38364926,  0.39849418],\n",
       "       [ 0.37832105,  0.40072232],\n",
       "       [ 0.38489377,  0.39761579],\n",
       "       [ 0.37822101,  0.40141997],\n",
       "       [ 0.38202506,  0.4021658 ],\n",
       "       [ 0.38264883,  0.4022705 ],\n",
       "       [ 0.37759018,  0.40271449],\n",
       "       [ 0.38460854,  0.40251172],\n",
       "       [ 0.37796441,  0.40279534],\n",
       "       [ 0.37852111,  0.40212941],\n",
       "       [ 0.38062426,  0.40106919],\n",
       "       [ 0.37769982,  0.40349549],\n",
       "       [ 0.37769014,  0.40325716],\n",
       "       [ 0.37773964,  0.40331459],\n",
       "       [ 0.37773055,  0.40387717],\n",
       "       [ 0.3779076 ,  0.40374714],\n",
       "       [ 0.377047  ,  0.40430632],\n",
       "       [ 0.37777019,  0.40411049],\n",
       "       [ 0.37756678,  0.40444171],\n",
       "       [ 0.37791783,  0.40441105]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1][121]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show the graph\n",
    "from func.jupyter_tensorboard import show_graph \n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.import_meta_graph('model_save/amadeus.meta')\n",
    "    graph = tf.get_default_graph()\n",
    "    show_graph(graph)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
